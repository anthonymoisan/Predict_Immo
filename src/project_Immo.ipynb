{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "398aa8cc",
   "metadata": {},
   "source": [
    "# Description du projet\n",
    "Le projet s'intéresse au prix de l'immobilier sur Paris. Est-on en mesure d'avoir une bonne prédiction sur la valeur mobilière d'un bien"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b3cc4a",
   "metadata": {},
   "source": [
    "# Lecture des jeux de données\n",
    "Les jeux de données sont disponibles sur https://www.data.gouv.fr/fr/datasets/demandes-de-valeurs-foncieres-geolocalisees/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04db751b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dddb88b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour lire les donnnées en fonction du fichier\n",
    "def ReadFile(nomFile, delimiter = '|'):\n",
    "    # lecture du fichier excel\n",
    "    df = pd.read_csv(nomFile, delimiter = delimiter, low_memory = False)\n",
    "    print(\"taille du jeu de donnees :\", df.shape)\n",
    "    return df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66eb3e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour extraire les données à partir d'un numéro de département\n",
    "def ExtractDepartement(df, numDep):\n",
    "    df['code_departement'].astype(str)\n",
    "    df['Validation'] = (df['code_departement'] == numDep )\n",
    "    dfDep = df[df['Validation']==True]\n",
    "    dfDep = dfDep.drop('Validation', axis=1)\n",
    "    print(\"Departement : {0}\".format(numDep))\n",
    "    print(\"Taille du jeu de donnees\", dfDep.shape)\n",
    "    return dfDep       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "408f2e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taille du jeu de donnees : (1429093, 40)\n"
     ]
    }
   ],
   "source": [
    "df1 = ReadFile(\"../input/AvecCoordonneesGeo/full.csv\", ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ec4b33f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taille du jeu de donnees : (4375223, 40)\n"
     ]
    }
   ],
   "source": [
    "df2 = ReadFile(\"../input/AvecCoordonneesGeo/full2021.csv\", ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c3af6e",
   "metadata": {},
   "source": [
    "## Concaténation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1a11eea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taille suite à union : (5804316, 40)\n"
     ]
    }
   ],
   "source": [
    "#Concaténation des deux jeux de données\n",
    "df = pd.concat([df1,df2])\n",
    "#,keys=['2022','2021'])\n",
    "#, names = ['FileInput', 'RowId'])\n",
    "print(\"taille suite à union :\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9e22b1",
   "metadata": {},
   "source": [
    "## Réduction à un département"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72bbded7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Departement : 75\n",
      "Taille du jeu de donnees (130696, 40)\n"
     ]
    }
   ],
   "source": [
    "dfDep = ExtractDepartement(df,'75')\n",
    "dfDepIni = dfDep\n",
    "# Enlever le commentaire pour générer le jeu de données pour Power BI\n",
    "dfDepIni.to_csv('../input/AvecCoordonneesGeo/dep752.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bd1aa9",
   "metadata": {},
   "source": [
    "# Nettoyage du jeu de données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e8e625",
   "metadata": {},
   "source": [
    "## Nettoyage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49af1e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Suppression des lignes en doublon\n",
    "dfDep.drop_duplicates(inplace=True)\n",
    "dfDep.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeaa9382",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Suppression des longitudes et latitudes null\n",
    "dfDep.drop(dfDep[(dfDep['longitude'].isnull()) | (dfDep['latitude'].isnull())].index, inplace=True)\n",
    "dfDep.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f49f49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Suppression des données où la valeur foncière est null\n",
    "dfDep.drop(dfDep[dfDep['valeur_fonciere'].isnull() ].index, inplace=True)\n",
    "dfDep.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abca2f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Suppression des valeurs foncières < 50KE et >3000KE\n",
    "dfDep.drop(dfDep[dfDep['valeur_fonciere']<50000 ].index, inplace=True)\n",
    "dfDep.drop(dfDep[dfDep['valeur_fonciere']>3000000 ].index, inplace=True)\n",
    "dfDep.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d655224",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Suppression des variables qui sont nulles pour 80% des valeurs\n",
    "listVariables = dfDep.isnull().sum() > (dfDep.shape[0]*0.8)\n",
    "listResultatsVarDrop = []\n",
    "for colname, serie in listVariables.iteritems():\n",
    "    if(serie == True):\n",
    "            listResultatsVarDrop.append(colname)\n",
    "listResultatsVarDrop\n",
    "dfDep.drop(listResultatsVarDrop, inplace=True, axis=1)\n",
    "dfDep.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e50211a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conversion des objets en string\n",
    "dfDep['adresse_nom_voie'] = dfDep['adresse_nom_voie'].astype(\"string\")\n",
    "dfDep['adresse_numero'] = dfDep['adresse_numero'].astype(\"string\")\n",
    "dfDep['nom_commune'] = dfDep['nom_commune'].astype(\"string\")\n",
    "dfDep['adresse_complete']=dfDep['adresse_numero']+' '+dfDep['adresse_nom_voie']+' , '+dfDep['nom_commune']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea96f3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Suppression des données où le type de local est une dépendance\n",
    "dfDep.drop(dfDep[dfDep['type_local']== 'Dépendance' ].index, inplace=True)\n",
    "dfDep.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee8e6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDep.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec427c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AggregationSimilarData(df):\n",
    "    \n",
    "    # Construction d'un dictionnaire \n",
    "    # où la clé est la chaine de caractère qui permet d'indiquer que deux lignes sont similaires\n",
    "    # où la valeur est l'index dans le dataframe initial\n",
    "    dict_similarData = {}\n",
    "    for index,series in df.iterrows():\n",
    "        keyRow = str(series['date_mutation'])+'_'+str(series['valeur_fonciere'])+'_'+series['adresse_complete']\n",
    "        if keyRow in dict_similarData:\n",
    "            listIndexSimilaire = dict_similarData[keyRow]\n",
    "            listIndexSimilaire.append(index)\n",
    "        else:\n",
    "            listKeyRow = list();\n",
    "            listKeyRow.append(index)\n",
    "            dict_similarData[keyRow] = listKeyRow\n",
    "    \n",
    "    #Suppression des valeurs dupliquées en prenant comme surface_reelle_bati le cumulé des surfaces\n",
    "    listIndexASupprimer = []\n",
    "    for cle,listIndex in dict_similarData.items():\n",
    "        if(len(listIndex)>1):\n",
    "            valSurfaceAgregee = df.at[listIndex[0],\"surface_reelle_bati\"]\n",
    "            val = 1\n",
    "            while (val != len(listIndex)):\n",
    "                listIndexASupprimer.append(listIndex[val])\n",
    "                valSurfaceAgregee += df.at[listIndex[val],\"surface_reelle_bati\"]\n",
    "                val += 1\n",
    "            df.at[listIndex[0],\"surface_reelle_bati\"] = valSurfaceAgregee\n",
    "    #print(listIndexASupprimer)\n",
    "    df.drop(listIndexASupprimer, inplace = True, axis = 0)\n",
    "    print(df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c45fb4a",
   "metadata": {},
   "source": [
    "## Gestion des doublons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257b8f3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "AggregationSimilarData(dfDep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903a35de",
   "metadata": {},
   "source": [
    "## Gestion des variables catégorielles\n",
    "On regarde les valeurs uniques pour identifier les variables catégorielles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c3fe90",
   "metadata": {},
   "outputs": [],
   "source": [
    "for colname, serie in dfDep.iteritems():\n",
    "    print(colname + \" has \" + str(serie.drop_duplicates().shape[0]) + \" unique values.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1062a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDep[\"nature_mutation\"] = pd.Categorical(dfDep[\"nature_mutation\"], ordered=False)\n",
    "dfDep[\"type_local\"] = pd.Categorical(dfDep[\"type_local\"], ordered=False)\n",
    "dfDep[\"nombre_pieces_principales\"] = pd.Categorical(dfDep[\"nombre_pieces_principales\"], ordered=False)\n",
    "dfDep[\"nom_commune\"] = pd.Categorical(dfDep[\"nom_commune\"], ordered=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbd7b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Suppression des variables qui semblent inutiles\n",
    "dfDep.drop(['code_departement', 'code_postal', 'adresse_code_voie', 'code_commune', 'id_parcelle','lot1_numero','lot2_numero', 'code_type_local'], inplace=True, axis=1)\n",
    "dfDep.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56775ac3",
   "metadata": {},
   "source": [
    "## Typage des variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad653d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDep['date_mutation'] = pd.to_datetime(dfDep['date_mutation'], format='%Y/%m/%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95d55ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfDep.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259a803d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conversion des objets en string\n",
    "dfDep['id_mutation'] = dfDep['id_mutation'].astype(\"string\")\n",
    "dfDep.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea9d651",
   "metadata": {},
   "source": [
    "# Exploration \n",
    "\n",
    "## Description univariée\n",
    "\n",
    "### La variable de temps\n",
    "On effectue du feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa1e3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDep['month']=dfDep[\"date_mutation\"].apply(lambda x: x.month)\n",
    "dfDep['day'] = dfDep[\"date_mutation\"].apply(lambda x: x.day)\n",
    "dfDep['year'] = dfDep[\"date_mutation\"].apply(lambda x: x.year)\n",
    "dfDep[\"month\"] = pd.Categorical(dfDep[\"month\"], ordered=True)\n",
    "dfDep[\"day\"] = pd.Categorical(dfDep[\"day\"], ordered=True)\n",
    "dfDep[\"year\"]= pd.Categorical(dfDep[\"year\"], ordered=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d437cea3",
   "metadata": {},
   "source": [
    "On va représenter les variables catégorielles à travers des tableaux de contingence ou des bars plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7889ac99",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDep[\"year\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e252a6d",
   "metadata": {},
   "source": [
    "On observe qu'on a pratiquement le double de données entre 2021 et 2022 ce qui est normal car on a une vision partielle de 2022 avec des données jusqu'à Juin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4087c6ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfDep[\"month\"].value_counts().sort_index().plot(kind=\"bar\")\n",
    "plt.title(\"Distribution des dates par mois\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ab56320d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba7bda57",
   "metadata": {},
   "source": [
    "On retrouve les données partielles. Par contre, il apparait difficile de faire des conclusions sur les mois hormi que le mois d'août semble relativement faible ce qui peut s'expliquer car les personnes sont en vacances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a190512c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDep[\"day\"].value_counts().sort_index().plot(kind=\"bar\")\n",
    "plt.title(\"Distribution des dates par jour\")\n",
    "plt.xlabel(\"Day\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff221714",
   "metadata": {},
   "source": [
    "Il semblerait qu'il y ait plus de ventes en milieu et fin de mois"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9f709e",
   "metadata": {},
   "source": [
    "### La cible de notre modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f194b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDep[\"valeur_fonciere\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70654189",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=dfDep['valeur_fonciere'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126c0069",
   "metadata": {},
   "source": [
    "On a clairement des problèmes d'échelle avec des outliers à supprimer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a07590",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Methode Remove outliers pour une loi biaisée\n",
    "def removeOutliers(variable):\n",
    "    print(\"avant \", dfDep.shape)\n",
    "    Q1 = dfDep[variable].quantile(0.25)\n",
    "    Q3 = dfDep[variable].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    dfDep.drop(dfDep[(dfDep[variable]<Q1 - 1.5*IQR) | (dfDep[variable]>Q3 + 1.5*IQR)].index, inplace=True)\n",
    "    print(\"après \",dfDep.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c51f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "removeOutliers('valeur_fonciere')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acacf1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Methode Remove outliers par une loi normale\n",
    "#Mean = dfDep['valeur_fonciere'].mean()\n",
    "#StandardDeviation = dfDep['valeur_fonciere'].std()\n",
    "#dfDep.drop(dfDep[(dfDep['valeur_fonciere']<Mean - 3*StandardDeviation) | (dfDep['valeur_fonciere']>Mean + 3*StandardDeviation)].index, inplace=True)\n",
    "#dfDep.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0138c39b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.boxplot(x=dfDep['valeur_fonciere'])\n",
    "dfDep['valeur_fonciere'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da8ed1f",
   "metadata": {},
   "source": [
    "### Les autres variables quantitatives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccdd2a9",
   "metadata": {},
   "source": [
    "Regardons les variables abérrantes sur les max sur les m2 et mettons une valeur max à 500 m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7197d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfDep.drop(dfDep[dfDep['surface_reelle_bati']>500].index, inplace=True, axis=0)\n",
    "#dfDep.drop(dfDep[dfDep['lot1_surface_carrez']>500].index, inplace=True, axis=0)\n",
    "#dfDep.shape\n",
    "#removeOutliers('surface_reelle_bati')\n",
    "#dfDep.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739392c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removeOutliers('lot1_surface_carrez')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c03955",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDep.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe910d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDep[\"prix m2\"]=dfDep[\"valeur_fonciere\"]/dfDep[\"surface_reelle_bati\"]\n",
    "sns.boxplot(x=dfDep['prix m2'])\n",
    "dfDep[\"prix m2\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddd43e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "removeOutliers(\"prix m2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b06ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDep[\"prix m2\"]=dfDep[\"valeur_fonciere\"]/dfDep[\"surface_reelle_bati\"]\n",
    "sns.boxplot(x=dfDep['prix m2'])\n",
    "dfDep.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0017484",
   "metadata": {},
   "outputs": [],
   "source": [
    "removeOutliers(\"lot1_surface_carrez\")\n",
    "sns.boxplot(x=dfDep['lot1_surface_carrez'])\n",
    "dfDep.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3245c1",
   "metadata": {},
   "source": [
    "Les données sur les variables quantitatives semblent cohérentes en terme de grandeur suite à différentes suppressions des données atypiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17028d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDep.drop([\"prix m2\"],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa08f46",
   "metadata": {},
   "source": [
    "### Les variables catégorielles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b65ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDep[\"nature_mutation\"].value_counts().sort_index().plot(kind=\"bar\")\n",
    "plt.title(\"Distribution selon les natures de mutation\")\n",
    "plt.xlabel(\"nature mutation\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69ff6dd",
   "metadata": {},
   "source": [
    "La plupart des biens sont des ventes. On va pouvoir supprimer cette variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7446cb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDep.drop(['nature_mutation'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3388cf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDep[\"type_local\"].value_counts().sort_index().plot(kind=\"bar\")\n",
    "plt.title(\"Distribution selon le type local\")\n",
    "plt.xlabel(\"type local\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad9f449",
   "metadata": {},
   "source": [
    "On peut se poser la question de la pertinence de cette variable car on a essentiellement deux modalités qui jouent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33376aa8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfDep[\"nombre_pieces_principales\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc90631",
   "metadata": {},
   "source": [
    "Ce champs apparait mal instancié avec des valeurs abberantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf103cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDep.drop(['nombre_pieces_principales'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec9e2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDep[\"nom_commune\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1408fe",
   "metadata": {},
   "source": [
    "### Conclusion sur l'analyse univariée\n",
    "\n",
    "On a pu voir que :\n",
    "* le jeu de données est constituée d'un an et demi d'historique\n",
    "* la target a été retravaillé pour éliminer les valeurs aberrantes. Il reste néanmoins des points atypiques sur le boxplot\n",
    "* on a rationnalisé certaines variables en enlevant des valeurs aberrantes ou en les éliminant de l'analyse pour certaines varaibles catégorielles.\n",
    "* on a introduit du feature ingeenering sur les dates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b6c92d",
   "metadata": {},
   "source": [
    "## Analyse bivariée\n",
    "\n",
    "L'analyse bivariée va consister à regarder l'influence de différentes variables sur la variable cible.\n",
    "\n",
    "### Les variables catégorielles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8865613",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"month\", y=\"valeur_fonciere\", kind=\"box\", data=dfDep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3278d9d4",
   "metadata": {},
   "source": [
    "Que cela soit en comparant month, year, day, les niveaux semblent relativement identiques mais on a beaucoup de points atypiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84ece67",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"type_local\", y=\"valeur_fonciere\", kind=\"box\", data=dfDep, orient=\"v\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538ce7d4",
   "metadata": {},
   "source": [
    "On peut constater que le prix des maisons est plus élevé que locaux industriels qui sont eux-mêmes à un niveau équivalent par rapport aux appartements en moyenne\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559463a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"nom_commune\", y=\"valeur_fonciere\", kind=\"box\", orient=\"v\",data=dfDep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334234f6",
   "metadata": {},
   "source": [
    "Les arrondissements semblent avoir un effet sur les prix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab62155e",
   "metadata": {},
   "source": [
    "### Les variables quantitatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea18f148",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDep.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d832f766",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,(ax1,ax2,ax3) = plt.subplots(ncols=3)\n",
    "fig.set_size_inches(14,10)\n",
    "sns.regplot(x=\"lot1_surface_carrez\",y=\"valeur_fonciere\",data=dfDep, ax=ax1)\n",
    "sns.regplot(x=\"nombre_lots\",y=\"valeur_fonciere\",data=dfDep,ax=ax2)\n",
    "sns.regplot(x=\"surface_reelle_bati\",y=\"valeur_fonciere\",data=dfDep,ax=ax3)\n",
    "#sns.regplot(x=\"Prix m2\",y=\"valeur_fonciere\",data=dfDep,ax=ax4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f46f3e",
   "metadata": {},
   "source": [
    "La valeur foncière augmente avec la surface, le nombre de lots, la surface réelle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605a61d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.heatmap(dfDep.corr(), cmap=\"YlOrRd\")\n",
    "plt.title(\"Corrélations des variables continues\")\n",
    "plt.show()\n",
    "dfDep.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4aca946",
   "metadata": {},
   "source": [
    "La valeur foncière est fortement corrélée à la surface carrez ou réelle, faiblement au nombre de lots et aux coordonnées gps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0076d18d",
   "metadata": {},
   "source": [
    "### Conclusion sur l'analyse bivariée\n",
    "\n",
    "La target est sensible : \n",
    "* à la surface réelle ou carrez\n",
    "* au prix du m2\n",
    "* à la commune\n",
    "Par contre, elle ne semble pas tellement sensible au mois, jour, année.\n",
    "La difficulté vient surtout du nombre de points atypiques importants."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599549af",
   "metadata": {},
   "source": [
    "## Analyse multivariée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfd6d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.relplot(x=\"lot1_surface_carrez\", y=\"surface_reelle_bati\", size=\"valeur_fonciere\", sizes=(15, 100), data=dfDep);\n",
    "#sns.catplot(x=\"lot1_surface_carrez\", y=\"valeur_fonciere\", hue=\"type_local\",kind=\"bar\",data=dfDep);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6beeeceb",
   "metadata": {},
   "source": [
    "# Modelisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1796b95",
   "metadata": {},
   "source": [
    "## Preprocessing pour scikit-learn¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c7d7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDep.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9718f4",
   "metadata": {},
   "source": [
    "### Gestion des données manquantes\n",
    "Les méthodes numériques d'apprentissage ne gèrent pas les NaN ou null sur les valeurs numériques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a73885",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDep.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e705a009",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDep.drop(['lot1_surface_carrez'],inplace=True, axis=1)\n",
    "dfDep.drop(dfDep[dfDep['surface_reelle_bati'].isna()].index, inplace=True, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26595404",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDep.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5fe76a",
   "metadata": {},
   "source": [
    "### Construction des ensembles X et y à partir du dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceda9645",
   "metadata": {},
   "source": [
    "On peut enlever l'id qui est un champ purement technique ainsi que la date et tous les éléments de type string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28eccbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDep[\"id_mutation\"].drop_duplicates(inplace=True)\n",
    "print(dfDep.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f809f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dfDep.drop([\"valeur_fonciere\",\"id_mutation\", \"date_mutation\", \"numero_disposition\", \"adresse_numero\", \"adresse_nom_voie\",\"adresse_complete\"], axis = 1)\n",
    "y = dfDep[\"valeur_fonciere\"]\n",
    "print(f\"Shape de X : {X.shape}\")\n",
    "print(f\"Shape de y : {y.shape}\")\n",
    "X.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d7c23e",
   "metadata": {},
   "source": [
    "### Preprocessing sur les variables catégorielles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4c6663",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = X.columns[X.dtypes == \"category\"].tolist()\n",
    "print(categorical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aabae2f",
   "metadata": {},
   "source": [
    "Scikit-learn ne reconnait pas les objets de type DataFrame directement, notamment les types catégoriels. Il faut donc préparer nos données afin que les méthodes de scikit-learn puissent les interpréter. Scikit learn requiert un encodage numérique des ces variables. Nous allons donc devoir encoder nos variables explicatives catégorielles à l'aide de variables indicatrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16be4e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummies =  pd.get_dummies(X[categorical_features], drop_first=True)\n",
    "X = pd.concat([X.drop(categorical_features, axis=1), df_dummies], axis=1)\n",
    "X.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50871e61",
   "metadata": {},
   "source": [
    "## Train, Test\n",
    "Nous utilisons scikit-learn pour faire le traitement et étant donné la volumétrie du jeu de données, nous allons prendre 80% pour le train et 20% pour le test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64481507",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=777)\n",
    "print(f\"Shape du X_train : {X_train.shape}\")\n",
    "print(f\"Shape du y_train : {y_train.shape}\")\n",
    "print(f\"Shape du X_test : {X_test.shape}\")\n",
    "print(f\"Shape du y_test : {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f1ebf5",
   "metadata": {},
   "source": [
    "## Preprocessing sur les variables numériques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e739cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = dfDep.columns[(dfDep.dtypes == \"int64\")].tolist() + dfDep.columns[(dfDep.dtypes == \"float64\")].tolist()\n",
    "print(numerical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8d28ec",
   "metadata": {},
   "source": [
    "Certaines méthodes d'apprentissage sont sensibles aux problèmes d'échelle sur les valeurs numériques. En preprocessing, on standardise les variables numériques en retranchant leur moyenne et en divisant par l'écart type via Scikit-learn. On réalise ce traitement sur l'ensemble d'apprentissage et on applique cette standardisation sur l'ensemble de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e53e259",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4740a4",
   "metadata": {},
   "source": [
    "## Un modèle simple : la régression linéaire\n",
    "\n",
    "Un premier modèle qui nous servira de *baseline*.\n",
    "\n",
    "Nous allons aussi introduire l'instanciation sur les données *train*, et nous validerons **ENSUITE** sur les données *test*.\n",
    "\n",
    "### Modèle de regression sur Train/Test\n",
    "$$y =\\sum_{i=1}^{n} a_i \\times x_i + b$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b163ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "reg = linear_model.LinearRegression()\n",
    "\n",
    "reg.fit(X_train_scaled, y_train)\n",
    "y_trainPred = reg.predict(X_train_scaled)\n",
    "y_testPred = reg.predict(X_test_scaled)\n",
    "print(f\"Score sur le train : {reg.score(X_train_scaled,y_train)}\")\n",
    "print(f\"Score sur le test : {reg.score(X_test_scaled,y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8fb5cd",
   "metadata": {},
   "source": [
    "La régression linéaire donne des résultats et il n'y a pas de phénomène de sur-apprentissage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8aa5988",
   "metadata": {},
   "source": [
    "## Coefficients de la régression linéaire\n",
    "\n",
    "Un des avantages de la régression linéaire est que nous pouvons obtenir les coefficients associés à chacune des variables. Nous pouvons voir les coefficients qui ont un impact sur le nombre de vélos loués.\n",
    "\n",
    "Regardons ces coefficients :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693935f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = pd.Series(reg.coef_.flatten(), index=X.columns).sort_values(ascending=False)\n",
    "coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d5cdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"ordonnee à l'origine : {reg.intercept_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d808411",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients[np.abs(coefficients)>10000].plot(kind=\"bar\")\n",
    "plt.title(\"Regression lineaire coefficient\")\n",
    "plt.ylabel(\"Coefficient value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ab7364",
   "metadata": {},
   "source": [
    "On retrouve des éléments de l'exploration. Certaines communes tirent le prix vers le base comme le 18ème, 19ème au contraire du 6ème, ... L'élément le plus prépondérant est la surface réellement bati. La lattitude et la longitude s'opposent en termes d'effet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0024e07",
   "metadata": {},
   "source": [
    "### Evaluation de la régression avec différentes métriques\n",
    "\n",
    "Nous allons regarder quelques métriques associées aux problématiques de régression :\n",
    "* L'erreur maximum entre la prédiction et la réalité\n",
    "* La moyenne des erreurs absolus entre la prédiction et la réalité\n",
    "* La moyenne des erreurs au carré entre la prédiction et la réalité (MSE)\n",
    "* Le score R2 qui est le coefficient de détermination en comparant MSE et la variance. Fonction renvoyée par la méthode score de Scikit Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ac0ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "def regression_metrics(y, y_pred):\n",
    "    return pd.DataFrame(\n",
    "        {\n",
    "            \"max_error\": metrics.max_error(y_true=y, y_pred=y_pred),\n",
    "            \"mean_absolute_error\": metrics.mean_absolute_error(y_true=y, y_pred=y_pred),\n",
    "            \"mean_squared_error\": metrics.mean_squared_error(y_true=y, y_pred=y_pred),\n",
    "            \"r2_score\": metrics.r2_score(y_true=y, y_pred=y_pred)\n",
    "        },\n",
    "        index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edc59d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Regression metrics for train data\")\n",
    "print(regression_metrics(y_train, y_trainPred))\n",
    "print(\"Regression metrics for test data\")\n",
    "print(regression_metrics(y_test, y_testPred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a527fbf0",
   "metadata": {},
   "source": [
    "Le modèle de regression linéaire n'est pas très bon quelque soit la métrique retenue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc4c794",
   "metadata": {},
   "source": [
    "## Arbre de décision et visions ensemblistes\n",
    "### Arbre de décision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291f33df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "decisionTree = DecisionTreeRegressor()\n",
    "decisionTree.fit(X_train_scaled, y_train)\n",
    "y_trainPred = decisionTree.predict(X_train_scaled)\n",
    "y_testPred = decisionTree.predict(X_test_scaled)\n",
    "print(f\"Score sur le train de l'arbre de décision : {decisionTree.score(X_train_scaled,y_train)}\")\n",
    "print(f\"Score sur le test de l'arbre de décision : {decisionTree.score(X_test_scaled,y_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a59743",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Regression metrics with Decision Tree for train data\")\n",
    "print(regression_metrics(y_train, y_trainPred))\n",
    "print(\"Regression metrics with Decision Tree for test data\")\n",
    "print(regression_metrics(y_test, y_testPred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2178bbe9",
   "metadata": {},
   "source": [
    "On est dans un cas de surapprentissage puisque l'arbre de décision \"fit\"  à l'ensemble de train mais ne se généralise pas bien sur l'ensemble de test. Néanmoins la performance est moins bonne que la régression linéaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a1c3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Feature importances : \\n{}\".format(decisionTree.feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869738b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importances(model):\n",
    "    n_features = X.shape[1]\n",
    "    plt.barh(range(n_features), model.feature_importances_, align = 'center')\n",
    "    plt.yticks(np.arange(n_features), X.columns)\n",
    "    plt.xlabel(\"Feature Importance\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    plt.ylim(-1,n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2c03fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_importances(decisionTree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a680ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresImportance = pd.Series(decisionTree.feature_importances_.flatten(), index=X.columns).sort_values(ascending=False)\n",
    "featuresImportance[(featuresImportance)>0.03].plot(kind=\"bar\")\n",
    "plt.title(\"Feature\")\n",
    "plt.ylabel(\"Feature Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354faaa1",
   "metadata": {},
   "source": [
    "On retrouve la surface réelle et la position géographique du bien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd1fcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for depth in range(5,20):\n",
    "    decisionTreeMaxDepth = DecisionTreeRegressor(max_depth=depth)\n",
    "    decisionTreeMaxDepth.fit(X_train_scaled, y_train)\n",
    "    print(f\"Max depth : {depth}\")\n",
    "    print(f\"Score sur le train de l'arbre de décision : {decisionTreeMaxDepth.score(X_train_scaled,y_train)}\")\n",
    "    print(f\"Score sur le test de l'arbre de décision : {decisionTreeMaxDepth.score(X_test_scaled,y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4a78e1",
   "metadata": {},
   "source": [
    "On observe assez vite le surapprentissage lorsqu'on augmente la profondeur de l'arbre\n",
    "\n",
    "Avantages : \n",
    "* On peut contrôler la complexité de l'arbre en jouant sur des paramètres avec la profondeur ou des stratégies d'élagage\n",
    "* Interprétabilité des décisions\n",
    "* Pas de problématique de prise en compte des échelles différentes entre les variables (même si dans notre cas, nous travaillons sur des données standardisées)\n",
    "\n",
    "Inconvénient majeur :\n",
    "* Même en jouant sur la complexité de l'arbre, un arbre tend au surapprentissage et fournit de piètre performance de généralisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55941355",
   "metadata": {},
   "source": [
    "### Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a5c290",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "nbTree = 100\n",
    "print(f\"Nombre d'arbres considérés : {nbTree}\")\n",
    "for depth in [5,10,15,20,30, 40]:\n",
    "    randomForest = RandomForestRegressor(n_estimators=nbTree, random_state=2, max_depth=depth)\n",
    "    randomForest.fit(X_train_scaled, y_train)\n",
    "    print(f\"--- Max depth : {depth}\")\n",
    "    print(f\"---------Score sur le train avec RandomForest : {randomForest.score(X_train_scaled,y_train)}\")\n",
    "    print(f\"---------Score sur le test avec RandomForest : {randomForest.score(X_test_scaled,y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c017dfa",
   "metadata": {},
   "source": [
    "On observe avec Random Forest une amélioration du score fonction de la profondeur considérées avec un surapprentissage de plus en plus important. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50ed62f",
   "metadata": {},
   "source": [
    "### GridSearch et Validation croisée\n",
    "\n",
    "Nous allons creuser un peu plus loin afin d'améliorer RandomForest en optimisant les hyperparamètres du modèle. Pour ce faire nous allons procéder par validation croisée avec 5 plis sur l'ensemble d'apprentissage. \n",
    "A l'aide de celle-ci, nous allons chercher quel(s) paramètre(s) nous donne(nt) le meilleur score et enfin nous évaluerons la qualité du modèle sur le jeu de données test.\n",
    "\n",
    "Les paramètres que nous allons chercher à optimiser dans RandomForest sont :\n",
    "* le paramètre max_depth qui correspond à la profondeur de l'arbre \n",
    "* le nombre d'arbres à considérer dans la forêt\n",
    "* le nombre de features maximale à considérer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadb839c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# grille de valeurs\n",
    "params = [{\"max_depth\": [10,15,20], \"n_estimators\": [100,200,300,500], \"max_features\": [12, 15, 20, 25]}]\n",
    "\n",
    "gridSearchCV = GridSearchCV(\n",
    "    RandomForestRegressor(),\n",
    "    params,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    return_train_score=True)\n",
    "gridSearchCV.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034c4e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Score sur le test : {:.2f}\".format(gridSearchCV.score(X_test_scaled,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3371aac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameters : {}\".format(gridSearchCV.best_params_))\n",
    "print(\"Best cross-validation score : {:.2f}\".format(gridSearchCV.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffdffbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best estimator:\\n{}\".format(gridSearchCV.best_estimator_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ea726d",
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresImportance = pd.Series(gridSearchCV.best_estimator_.feature_importances_.flatten(), index=X.columns).sort_values(ascending=False)\n",
    "featuresImportance[(featuresImportance)>0.03].plot(kind=\"bar\")\n",
    "plt.title(\"Feature\")\n",
    "plt.ylabel(\"Feature Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9cfa0d",
   "metadata": {},
   "source": [
    "A travers une validation croisée et un grid search, on obtient un paramétrage via Random Forest et on peut visualiser les variables qui ont de l'importance. On retrouve des variables explicatives en lien avec notre analyse exploratoire. On est aussi dans un cas où il n'y a pas de surapprentissage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbbf8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_testPred = gridSearchCV.best_estimator_.predict(X_test_scaled)\n",
    "print(\"Regression metrics pour la forêt aléatoire optimisée for test data\")\n",
    "print(regression_metrics(y_test, y_testPred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1e6437",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trainPred = gridSearchCV.best_estimator_.predict(X_train_scaled)\n",
    "print(\"Regression metrics pour la forêt aléatoire optimisée for train data\")\n",
    "print(regression_metrics(y_train, y_trainPred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f908e1",
   "metadata": {},
   "source": [
    "## Sauvegarde du modèle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed9eee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860e7be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dump(gridSearchCV.best_estimator_.predict, 'sauvegardeModele.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e031c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf = load('sauvegardeModele.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31900e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf.predict(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243c6727",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "## Sur le travail réalisé\n",
    "* L'analyse univariée et multivariée ont permis de mettre en évidence des liens entre les variables explicatives et à expliquer\n",
    "* Le featuring Ingeenering a été un travail réalisé sur les dates pour essayer de voir les liens avec la variable à prédire.\n",
    "* Les modèles linéaires donne des résultats pas très intéressants sur certaines métriques\n",
    "* Un modèle basé sur des arbres de décision permet d'obtenir des meilleurs résultats par rapport à la regression linéaire. Une optimisation des paramètres a pu être mise en oeuvre via validation croisée et grille de recherche\n",
    "\n",
    "## Sur les perspectives\n",
    "* Sur le code : la mise en place de Pipe avec l'utilisation de OneHotEncoder et StandardScaler.\n",
    "* Sur les modèles : tester d'autres modèles pour améliorer la prévision. On peut penser à une régression polynomiale ou boosting d'arbres de régression, ou des modèles traitant spécifiquement de séries temporelles.\n",
    "* Un traitement des points atypiques a été réalisé avec aussi de l'imputation mais il faudrait passer plus de temps sur la compréhension des données."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
